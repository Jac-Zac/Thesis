{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c5947f1-5e6f-4f97-9330-06e3f4dba400",
   "metadata": {},
   "source": [
    "# Notebook to run the model on unseen images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12be7d-a57f-4877-8eab-ee3b2f0e427e",
   "metadata": {},
   "source": [
    "### Install necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac7e13-4e87-4fd7-96e0-d8a5aabf099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets sentencepiece\n",
    "!pip install -q pytorch-lightning wandb\n",
    "!pip install -q donut-python\n",
    "\n",
    "# !huggingface-cli login this shouldh be done from the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e23404-c018-4a47-8c11-5e628f8b7908",
   "metadata": {},
   "source": [
    "## Resize the images\n",
    "\n",
    "I want to have the images in the correct size and flip them on the correct side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e99b72-6cca-471e-a858-00d9cba72bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ExifTags\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define the paths for the input and output directories\n",
    "input_dir = \"img\"\n",
    "output_dir = \"img_resized/\"\n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Loop through all the image files in the input directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        # Open the image and resize it\n",
    "        with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "            resized_img = img.resize((1600, 1200))\n",
    "            \n",
    "            # Check if the image has orientation metadata and rotate it if necessary\n",
    "            for orientation in ExifTags.TAGS.keys():\n",
    "                if ExifTags.TAGS[orientation] == 'Orientation':\n",
    "                    if hasattr(img, '_getexif'):\n",
    "                        exif = dict(img._getexif().items())\n",
    "                        if exif[orientation] == 3:\n",
    "                            resized_img = resized_img.rotate(180, expand=True)\n",
    "                        elif exif[orientation] == 6:\n",
    "                            resized_img = resized_img.rotate(270, expand=True)\n",
    "                        elif exif[orientation] == 8:\n",
    "                            resized_img = resized_img.rotate(90, expand=True)\n",
    "                    break\n",
    "            \n",
    "            # Save the resized image to the output directory with correct orientation metadata\n",
    "            resized_img.save(os.path.join(output_dir, filename), exif=img.info.get('exif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd632a29-c874-4367-8897-f8427d52a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "# Using the model that I think works the best and generalize which is epoch 9 of the last run (very similar to epoch 10)\n",
    "processor = DonutProcessor.from_pretrained(\"Jac-Zac/thesis_test_donut\",  revision=\"8c5467cb66685e801ec6ff8de7e7fdd247274ed0\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"Jac-Zac/thesis_test_donut\",  revision=\"8c5467cb66685e801ec6ff8de7e7fdd247274ed0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa831e29-7da2-4187-b30c-a071f1578f34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51de0daf70e43749199e8a253564cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1553 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d466ec6863504c0bad27f0ca4c0c4d5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4f14a3b642473a8464b16d20844e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/Users/jaczac/.cache/huggingface/datasets/imagefolder/img_resized-7f5590504a871c24/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec24c3e25bba4b7c959ed578280afb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from donut import JSONParseEvaluator\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "output_list = []\n",
    "accs = []\n",
    "\n",
    "image_path = \"img_resized\"\n",
    "\n",
    "# Load the dataset as a dataset\n",
    "dataset = load_dataset(image_path,)\n",
    "\n",
    "# Iterate over all the images\n",
    "for idx, sample in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    # prepare encoder inputs\n",
    "    pixel_values = processor(sample[\"image\"].convert(\"RGB\"), return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    # prepare decoder inputs\n",
    "    task_prompt = \"<s_herbarium>\"\n",
    "    decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "    decoder_input_ids = decoder_input_ids.to(device)\n",
    "    \n",
    "    # autoregressively generate sequence\n",
    "    outputs = model.generate(\n",
    "            pixel_values,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            max_length=model.decoder.config.max_position_embeddings,\n",
    "#            early_stopping=True,\n",
    "            pad_token_id=processor.tokenizer.pad_token_id,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id,\n",
    "            use_cache=True,\n",
    "            num_beams=1,\n",
    "            bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "\n",
    "    # turn into JSON\n",
    "    seq = processor.batch_decode(outputs.sequences)[0]\n",
    "    seq = seq.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
    "    seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
    "    seq = processor.token2json(seq)\n",
    "\n",
    "    output_list.append({\"sample_id\": idx, \"prediction\": seq})\n",
    "    \n",
    "# Save output to JSON file\n",
    "output_file_path = \"../output.json\"  # Replace with your desired output file path\n",
    "with open(output_file_path, \"w\") as f:\n",
    "    json.dump(output_list, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
