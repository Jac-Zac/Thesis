{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac7e13-4e87-4fd7-96e0-d8a5aabf099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets sentencepiece\n",
    "!pip install -q pytorch-lightning wandb\n",
    "!pip install -q donut-python\n",
    "\n",
    "# !huggingface-cli login this shouldh be done from the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd632a29-c874-4367-8897-f8427d52a9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c6bf2b7f3241259618a507e27cb529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/809M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = DonutProcessor.from_pretrained(\"Jac-Zac/thesis_test_donut\", revision = 'c13aef46a13c2646b315bf37bb6bfa38033a48db')\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"Jac-Zac/thesis_test_donut\", revision = 'c13aef46a13c2646b315bf37bb6bfa38033a48db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa831e29-7da2-4187-b30c-a071f1578f34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa1b71dd2304b9d8784be57798d92cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1553 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8252eefc851f45aeaebe4122665a2734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658bbecfc54e4beb8359c92cdaf14bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (/Users/jaczac/.cache/huggingface/datasets/imagefolder/img_resized-7f5590504a871c24/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e4de72bd0c463cbea2080d460d5061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracies': [0.7297297297297297, 0.6060606060606061, 0.23728813559322037, 0.6965517241379311, 0.7857142857142857, 0.8253968253968254, 0.05208333333333337, 1.0, 0.8, 0.696969696969697, 0.8717948717948718, 0.7, 0.5686274509803921, 0.6019417475728155, 0.44285714285714284, 0.3538461538461538, 0.608, 0.375, 0.5593220338983051, 0.6551724137931034, 0.23076923076923073, 0.589041095890411, 0, 0.8961038961038961, 0.14432989690721654, 0.3893805309734514, 0.6194690265486726, 0.7604166666666666, 0.908256880733945, 0.851063829787234, 0.8613861386138614, 1.0, 0.8571428571428572, 0, 0.5421686746987953, 0.3362068965517241, 0.5941176470588235, 0.33684210526315794, 1.0, 0.8272727272727273, 0.9125, 0.8818181818181818, 0.53125, 0.9743589743589743, 0.8048780487804879, 1.0, 1.0, 0.9159663865546218, 0.7571428571428571, 0.8676470588235294, 0.8117647058823529, 0.8674698795180723, 0.9745222929936306, 0.9739130434782609, 0.868421052631579, 0.8840579710144928, 1.0, 0.6634615384615384, 0.7972972972972973, 0.8089887640449438, 0.8554216867469879, 0.6867469879518072, 0.9620253164556962, 0.9558823529411765, 0.5606060606060606, 1.0, 0.7752808988764045, 0.37209302325581395, 0.14935064935064934, 0.09259259259259256, 0.5585585585585586, 0.9886363636363636, 0, 0, 0.38834951456310685, 1.0, 0.8552631578947368, 0.7792207792207793, 0.7272727272727273, 0.7931034482758621, 0.9375, 0.8220338983050848, 0.6372549019607843, 0.9893617021276596, 0.978494623655914, 1.0, 0.5434782608695652, 0.9805825242718447, 0.987012987012987, 0.9859154929577465, 0.9166666666666666, 0.8405797101449275, 0.9333333333333333, 1.0, 0.875, 0.5602836879432624, 0.967479674796748, 0.8990825688073394, 0.9495798319327731, 0.7547169811320755, 0.6538461538461539, 0.811965811965812, 0.7142857142857143, 0.26277372262773724, 0.26490066225165565, 0.6666666666666667, 0.9940828402366864, 0.8981481481481481, 0.8387096774193549, 0.865979381443299, 0.978494623655914, 0.6868686868686869, 0.7010309278350515, 0.9017857142857143, 1.0, 0.9203539823008849, 0.9491525423728814, 0.7941176470588236, 0.7938144329896908, 0.8796296296296297, 0.8073394495412844, 0.990990990990991, 0.2314814814814815, 0.8375, 0.9583333333333334, 0.9295774647887324, 0.5714285714285714, 0, 0.8645833333333334, 0.43333333333333335, 0.7959183673469388, 0.9896907216494846, 0.8735632183908046, 0.8857142857142857, 0.5483870967741935, 0, 0.31343283582089554, 0.15517241379310343], 'mean_accuracy': 0.7103449067622407} length : 138\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "from donut import JSONParseEvaluator\n",
    "from datasets import load_dataset\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "output_list = []\n",
    "accs = []\n",
    "\n",
    "image_path = \"/Users/jaczac/Github/Thesis/donut_example/small_copy/img_resized\"\n",
    "\n",
    "dataset = load_dataset(image_path, split=\"test\")\n",
    "\n",
    "\n",
    "for idx, sample in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    # prepare encoder inputs\n",
    "    pixel_values = processor(sample[\"image\"].convert(\"RGB\"), return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    # prepare decoder inputs\n",
    "    task_prompt = \"<s_herbarium>\"\n",
    "    decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "    decoder_input_ids = decoder_input_ids.to(device)\n",
    "    \n",
    "    # autoregressively generate sequence\n",
    "    outputs = model.generate(\n",
    "            pixel_values,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            max_length=model.decoder.config.max_position_embeddings,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=processor.tokenizer.pad_token_id,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id,\n",
    "            use_cache=True,\n",
    "            num_beams=1,\n",
    "            bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "\n",
    "    # turn into JSON\n",
    "    seq = processor.batch_decode(outputs.sequences)[0]\n",
    "    seq = seq.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
    "    seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
    "    seq = processor.token2json(seq)\n",
    "\n",
    "    ground_truth = json.loads(sample[\"ground_truth\"])\n",
    "    \n",
    "    # modify ground_truth to replace \" \" with \"\" since I would still count it as a correct prediction\n",
    "    ground_truth = json.loads(sample[\"ground_truth\"].replace('\" \"', '\"\"'))\n",
    "    \n",
    "    evaluator = JSONParseEvaluator()\n",
    "    score = evaluator.cal_acc(seq, ground_truth)\n",
    "\n",
    "    accs.append(score)\n",
    "    output_list.append(seq)\n",
    "\n",
    "scores = {\"accuracies\": accs, \"mean_accuracy\": np.mean(accs)}\n",
    "print(scores, f\"length : {len(accs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ce695c8-2ecb-4d82-9253-e8feb127aed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7103449067622407\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy:\", np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eca271-9024-4a77-b9ad-9809212f94fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Mean accuracy:\", np.median(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2822bb-75f7-4615-abda-f868461c5ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get indices of worst 5 predictions\n",
    "worst_idxs = np.argsort(accs)[:5].tolist()\n",
    "\n",
    "# prepare decoder inputs\n",
    "task_prompt = \"<s_herbarium>\"\n",
    "decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "decoder_input_ids = decoder_input_ids.to(device)\n",
    "\n",
    "for idx in worst_idxs:\n",
    "    sample = dataset[idx]\n",
    "\n",
    "    # prepare encoder inputs\n",
    "    pixel_values = processor(sample[\"image\"].convert(\"RGB\"), return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "\n",
    "    # autoregressively generate sequence\n",
    "    outputs = model.generate(\n",
    "        pixel_values,\n",
    "        decoder_input_ids=decoder_input_ids,\n",
    "        max_length=model.decoder.config.max_position_embeddings,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=processor.tokenizer.pad_token_id,\n",
    "        eos_token_id=processor.tokenizer.eos_token_id,\n",
    "        use_cache=True,\n",
    "        num_beams=1,\n",
    "        bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "        return_dict_in_generate=True,\n",
    "    )\n",
    "\n",
    "    # turn into JSON\n",
    "    seq = processor.batch_decode(outputs.sequences)[0]\n",
    "    seq = seq.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
    "    seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
    "    seq = processor.token2json(seq)\n",
    "    \n",
    "    print(f\"Ground Truth: {sample['ground_truth']}\\n\")\n",
    "    print(f\"Prediction: {seq}\\n\")\n",
    "    print(f\"Score: {accs[idx]}\\n\")\n",
    "    display(sample[\"image\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
