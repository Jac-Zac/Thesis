{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dac7e13-4e87-4fd7-96e0-d8a5aabf099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets sentencepiece\n",
    "!pip install -q pytorch-lightning wandb\n",
    "!pip install -q donut-python\n",
    "\n",
    "# MPS acceleration is available on MacOS 12.3+\n",
    "!pip3 install -q --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "\n",
    "# !huggingface-cli login this shouldh be done from the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd632a29-c874-4367-8897-f8427d52a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DonutProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "processor = DonutProcessor.from_pretrained(\"Jac-Zac/thesis_donut\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"Jac-Zac/thesis_donut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac51dd2-1b50-4d4f-ae56-142d0b7162c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa831e29-7da2-4187-b30c-a071f1578f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import wandb\n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "from donut import JSONParseEvaluator\n",
    "from datasets import load_dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Check that MPS is available\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "else:\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "\n",
    "# Modify the table columns to include the desired keys\n",
    "table = wandb.Table(columns=[\"Image\", \"Prediction_Nome_verbatim\", \"Prediction_Date\", \"Prediction_Elevation\", \"Prediction_Locality\", \n",
    "                             \"Ground_Truth_Nome_verbatim\", \"Ground_Truth_Date\", \"Ground_Truth_Elevation\", \"Ground_Truth_Locality\", \n",
    "                             \"Name_Edit_Distance\", \"Scores\"])\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "output_list, accs = [], []\n",
    "\n",
    "image_path = \"img_resized\"\n",
    "\n",
    "dataset = load_dataset(image_path, split=\"validation\")\n",
    "\n",
    "api_key = \"api_key\"\n",
    "wandb.login(key=api_key)\n",
    "wandb.init(project=\"Donut\", name=\"validation_set\")\n",
    "\n",
    "for idx, sample in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    # Do some execption handling for wierd files\n",
    "    try:\n",
    "        # Load the image\n",
    "        image = sample[\"image\"].convert(\"RGB\")\n",
    "        \n",
    "        # Check if the image is truncated\n",
    "        image.load()\n",
    "    except OSError as e:\n",
    "        if \"image file is truncated\" in str(e):\n",
    "            print(f\"Warning: Skipping truncated image\")\n",
    "            continue\n",
    "        else:\n",
    "            raise\n",
    "                \n",
    "    # prepare encoder inputs\n",
    "    pixel_values = processor(sample[\"image\"].convert(\"RGB\"), return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "    # prepare decoder inputs\n",
    "    task_prompt = \"<s_herbarium>\"\n",
    "    decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "    decoder_input_ids = decoder_input_ids.to(device)\n",
    "        \n",
    "    # autoregressively generate sequence\n",
    "    outputs = model.generate(\n",
    "            pixel_values,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            max_length=model.decoder.config.max_position_embeddings,\n",
    "            early_stopping=True,\n",
    "            pad_token_id=processor.tokenizer.pad_token_id,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id,\n",
    "            use_cache=True,\n",
    "            num_beams=1,\n",
    "            bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "            return_dict_in_generate=True,\n",
    "        )\n",
    "\n",
    "    # turn into JSON\n",
    "    seq = processor.batch_decode(outputs.sequences)[0]\n",
    "    seq = seq.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
    "    seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
    "    seq = processor.token2json(seq)\n",
    "    \n",
    "    ground_truth = json.loads(sample[\"ground_truth\"])\n",
    "    evaluator = JSONParseEvaluator()\n",
    "    score = evaluator.cal_acc(seq, ground_truth)\n",
    "\n",
    "    accs.append(score)\n",
    "    output_list.append(seq)\n",
    "    \n",
    "    # Avoid unexpected preditction errors:\n",
    "    try:\n",
    "        if score <= 0.2:\n",
    "            image = sample[\"image\"].convert(\"RGB\").resize((900, 1200))\n",
    "            pred = seq\n",
    "            gt = json.loads(sample[\"ground_truth\"])\n",
    " \n",
    "            # Merge Day, Month, and Year for prediction and ground truth\n",
    "            pred_date = f\"{pred.get('Day', '')}/{pred.get('Month', '')}/{pred.get('Year', '')}\"\n",
    "            gt_date = f\"{gt.get('Day', '')}/{gt.get('Month', '')}/{gt.get('Year', '')}\"\n",
    "\n",
    "            # Compute edit distance for Nome_verbatim\n",
    "            name_edit_dist = evaluator.cal_acc(pred.get('Nome_verbatim', ''), gt.get('Nome_verbatim', ''))\n",
    "\n",
    "            # Convert the image to a wandb.Image object\n",
    "            image_wandb = wandb.Image(image)\n",
    "\n",
    "            # Add data to the table in the desired format\n",
    "            table.add_data(\n",
    "                image_wandb,\n",
    "                pred.get('Nome_verbatim', ''),\n",
    "                pred_date,\n",
    "                pred.get('Elevation', ''),\n",
    "                pred.get('Locality', ''),\n",
    "                gt.get('Nome_verbatim', ''),\n",
    "                gt_date,\n",
    "                gt.get('Elevation', ''),\n",
    "                gt.get('Locality', ''),\n",
    "                name_edit_dist,\n",
    "                score\n",
    "            )\n",
    "    except TypeError as e:\n",
    "        # Extract the file name from the file path\n",
    "        print(f\"Warning: Skipping sample number: {idx} due to error: {e}\")\n",
    "        \n",
    "wandb.log({\"worst_predictions\": table})\n",
    "\n",
    "scores = {\"accuracies\": accs, \"mean_accuracy\": np.mean(accs)}\n",
    "print(scores, f\"length : {len(accs)}\")\n",
    "print(\"Median accuracy:\", np.median(accs))\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce695c8-2ecb-4d82-9253-e8feb127aed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Mean accuracy:\", np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b87f03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Mean accuracy:\", np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eca271-9024-4a77-b9ad-9809212f94fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Mean accuracy:\", np.median(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc6df2-d0f4-42fc-9a8e-87a9443aea20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean_without_worst = np.mean(np.sort(accs)[10:])\n",
    "print(\"Mean accuracy (excluding worst 10):\", mean_without_worst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2822bb-75f7-4615-abda-f868461c5ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get indices of worst 5 predictions\n",
    "worst_idxs = np.argsort(accs)[:100].tolist()\n",
    "\n",
    "# prepare decoder inputs\n",
    "task_prompt = \"<s_herbarium>\"\n",
    "decoder_input_ids = processor.tokenizer(task_prompt, add_special_tokens=False, return_tensors=\"pt\").input_ids\n",
    "decoder_input_ids = decoder_input_ids.to(device)\n",
    "\n",
    "for idx in worst_idxs:\n",
    "    sample = dataset[idx]\n",
    "\n",
    "    # prepare encoder inputs\n",
    "    pixel_values = processor(sample[\"image\"].convert(\"RGB\"), return_tensors=\"pt\").pixel_values\n",
    "    pixel_values = pixel_values.to(device)\n",
    "\n",
    "    # autoregressively generate sequence\n",
    "    outputs = model.generate(\n",
    "        pixel_values,\n",
    "        decoder_input_ids=decoder_input_ids,\n",
    "        max_length=model.decoder.config.max_position_embeddings,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=processor.tokenizer.pad_token_id,\n",
    "        eos_token_id=processor.tokenizer.eos_token_id,\n",
    "        use_cache=True,\n",
    "        num_beams=1,\n",
    "        bad_words_ids=[[processor.tokenizer.unk_token_id]],\n",
    "        return_dict_in_generate=True,\n",
    "    )\n",
    "\n",
    "    # turn into JSON\n",
    "    seq = processor.batch_decode(outputs.sequences)[0]\n",
    "    seq = seq.replace(processor.tokenizer.eos_token, \"\").replace(processor.tokenizer.pad_token, \"\")\n",
    "    seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()  # remove first task start token\n",
    "    seq = processor.token2json(seq)\n",
    "    \n",
    "    print(f\"Ground Truth: {sample['ground_truth']}\\n\")\n",
    "    print(f\"Prediction: {seq}\\n\")\n",
    "    print(f\"Score: {accs[idx]}\\n\")\n",
    "    display(sample[\"image\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
