{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403aeae7-5499-4cfd-b5e6-c75fb3270760",
   "metadata": {},
   "source": [
    "# Version for the old dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902fdb4e-9a95-4e76-b20c-bab9332198d9",
   "metadata": {},
   "source": [
    "### Formatting the dataset lables\n",
    "\n",
    "We import the dataset lables in the format given to us in `xlsx` and load them into a pandas dataframe to be able to work with the with more ease. We also do some cleanup by setting NaN for unlabled tags. Also somewhere around line 226 or 266 i think i had to change a Day from 26 14 to 26-14 since I'm looking for spaces to identify the days that were wrongly interpreted as dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524082c-ea1a-4416-ac1a-f7b4fe9fb52d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the xlsx file\n",
    "df = pd.read_excel('../data/lables.xlsx')\n",
    "\n",
    "# Replace all occurrences of 'x' with NaN\n",
    "df.replace('x', np.NaN, inplace=True)\n",
    "\n",
    "columns_to_format = ['Giorno', 'Mese', 'Anno', 'Altitudine']\n",
    "\n",
    "# Drop the lines were an error occurs for know\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        # Loop through the different fields to which we want to apply it\n",
    "        for column in columns_to_format:\n",
    "            if pd.notna(row[column]):\n",
    "                row[column] = pd.to_datetime(row[column], errors='coerce').strftime('%-d-%-m')\n",
    "    except ValueError:\n",
    "        # Drop the rows that are too wierd\n",
    "        df.drop(index, inplace=True)\n",
    "        \n",
    "# Change the days where they where automatically formatted to dates for two different fields\n",
    "for column in columns_to_format:\n",
    "    df[column] = df[column].apply(lambda x: pd.to_datetime(x, errors='coerce').strftime('%-d-%-m') if (not pd.isna(x) and ' ' in str(x)) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e865581e-f35f-4a08-9856-4442f29624e4",
   "metadata": {},
   "source": [
    "### Creating the metadata.json\n",
    "\n",
    "We have a folder with images and we want to create the `metadata.json` file  which associate text from the dataframe to the images as ground truth. This is necessary for the `imagefolder` feature of `datasets`.\n",
    "    \n",
    "The `metadata.json` should look at the end similar to the example below.\n",
    "\n",
    "```json\n",
    "    {\"file_name\": \"0001.png\", \"ground_truth\": \"This is a golden retriever playing with a ball\"}\n",
    "    {\"file_name\": \"0002.png\", \"ground_truth\": \"A german shepherd\"}\n",
    "```\n",
    "In our example will `\\\"text\\\"` column contain the OCR text of the image, which will later be used for creating the Donut specific format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eacc6ac-f65d-4ed4-8f78-745c627f0fea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "\n",
    "# define paths\n",
    "image_path = \"../data/img/\"\n",
    "\n",
    "# define metadata list\n",
    "metadata_list = []\n",
    "\n",
    "# loop through rows of dataframe\n",
    "for index, row in df.iterrows():\n",
    "    # Do it only for the ones who have null note and others to avoid wierd things\n",
    "    if pd.isnull(row['Note']) and pd.isnull(row['Determinavit']) and pd.isnull(row['Legit']):\n",
    "       \n",
    "        # Fill the NaN in the row wiht the empty string\n",
    "        row = row.fillna(' ')\n",
    "        \n",
    "        # create dictionary with metadata for this row\n",
    "        metadata_dict = {\n",
    "            \"Nome_verbatim\": row['Nome_verbatim'],\n",
    "            \"Locality\": row['Localit√† di raccolta'],\n",
    "            \"Elevation\": row['Altitudine'],\n",
    "            \"Day\": row['Giorno'],\n",
    "            \"Month\": row['Mese'],\n",
    "            \"Year\": row['Anno'],\n",
    "        }\n",
    "        # create dictionary with \"file_name\" and \"text\" keys\n",
    "        metadata_list.append({\n",
    "            \"ground_truth\": json.dumps(metadata_dict),\n",
    "            \"file_name\": f\"{str(row['ID']).zfill(5)}.jpg\"\n",
    "        })\n",
    "\n",
    "# write jsonline file to the image_path\n",
    "jsonl_file_path = os.path.join(image_path, 'metadata.jsonl')\n",
    "with open(jsonl_file_path, 'w') as outfile:\n",
    "    for entry in metadata_list:\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d08d99-db31-4d6b-9400-8ab05b7bb9b4",
   "metadata": {
    "id": "T3syA6vQunre"
   },
   "source": [
    "#### Delete images that are not in the metadata.json\n",
    "\n",
    "---\n",
    "\n",
    "After I have created a copy I can delete the images that are not in the metadata from the folder that I actually use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b563bfa-71eb-4b90-aa1c-fa8015d9ec29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "image_path = \"../data/img/\"\n",
    "metadata_file = image_path + \"metadata.jsonl\"\n",
    "\n",
    "# Load the list of image files from the metadata file\n",
    "with open(metadata_file, 'r') as f:\n",
    "    metadata_list = [json.loads(line)['file_name'] for line in f]\n",
    "\n",
    "# Count the number of deleted files\n",
    "deleted_count = 0\n",
    "\n",
    "# Create a progress bar\n",
    "with tqdm(total=len(os.listdir(image_path)), desc=\"Going through files\") as pbar:\n",
    "    # Delete image files that don't have metadata\n",
    "    for file_name in os.listdir(image_path):\n",
    "        if file_name.endswith('.jpg') and file_name not in metadata_list:\n",
    "            os.remove(os.path.join(image_path, file_name))\n",
    "            deleted_count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "print(f\"Number of files deleted: {deleted_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bacc1d9-dc39-490d-9720-8cdb9344c3c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Smaller image size dataset\n",
    "\n",
    "Create a copy of the images with a half of the size and rotate them in necessary do everything with a progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04971705-2147-44b9-bf0c-55b9605bc3ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import shutil\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_dir = \"../data/img/\"\n",
    "output_dir = \"../data/img_resized\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "image_files = [filename for filename in os.listdir(input_dir) if filename.endswith(\".jpg\")]\n",
    "\n",
    "metadata_file = input_dir + \"metadata.jsonl\"\n",
    "metadata = []\n",
    "\n",
    "with open(metadata_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        metadata.append(json.loads(line))\n",
    "\n",
    "updated_metadata = []\n",
    "\n",
    "for filename in tqdm(image_files, desc=\"Processing images\"):\n",
    "    try:\n",
    "        with Image.open(os.path.join(input_dir, filename)) as img:\n",
    "            resized_img = img.resize((1600, 1200))\n",
    "            \n",
    "            exif_data = img.info.get('exif')\n",
    "            if exif_data is not None:\n",
    "                resized_img.save(os.path.join(output_dir, filename), exif=exif_data)\n",
    "            else:\n",
    "                resized_img.save(os.path.join(output_dir, filename))\n",
    "\n",
    "            for entry in metadata:\n",
    "                if entry[\"file_name\"] == filename:\n",
    "                    updated_metadata.append(entry)\n",
    "                    break\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {filename}\")\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Cannot identify image file: {filename}\")\n",
    "\n",
    "with open(os.path.join(output_dir, \"metadata.jsonl\"), \"w\") as f:\n",
    "    for entry in updated_metadata:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "# shutil.copyfile(metadata_file, \"img_resized/metadata.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
